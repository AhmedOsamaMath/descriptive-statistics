# Bayesian Statistics

**Bayesian statistics** is a statistical framework that incorporates prior knowledge or beliefs, along with new evidence, to update the probability of an event. It is based on **Bayes' theorem**, a fundamental rule for updating probabilities in light of new data.

---

## Key Concepts

1. **Prior Probability ( $P(A)$ )**:  
   The initial belief about the probability of an event before observing new data.  

2. **Likelihood ( $P(B \mid A)$ )**:  
   The probability of observing the data given the event $A$.  

3. **Posterior Probability ( $P(A \mid B)$ )**:  
   The updated probability of the event after considering the evidence.  

4. **Bayes’ Theorem**:  
   The mathematical formula for updating probabilities:

   $$P(A \mid B) = \frac{P(B \mid A) \cdot P(A)}{P(B)}$$

   Where:
   
   - $P(A \mid B)$: Posterior probability  
   - $P(B \mid A)$: Likelihood  
   - $P(A)$: Prior probability  
   - $P(B)$: Evidence probability  

---

## Steps in Bayesian Inference

1. **Define the Prior ( $P(A)$ )**:  
   Specify the initial belief about the parameter or hypothesis.  

2. **Specify the Likelihood ( $P(B \mid A)$ )**:  
   Model how the observed data would be distributed given the hypothesis.  

3. **Update to the Posterior ( $P(A \mid B)$ )**:  
   Use Bayes' theorem to calculate the updated probabilities.  

4. **Interpret the Results**:  
   Analyze the posterior distribution to draw conclusions or make predictions.  

---

## Example: Diagnosing a Disease

### Problem:

A medical test for a disease has:  

- Sensitivity (true positive rate): 95%  
- Specificity (true negative rate): 90%  

The prevalence of the disease is 1% in the population. What is the probability that a person has the disease if they test positive?

### Solution:

1. **Define Events**:  
   - $A$: Person has the disease.  
   - $B$: Person tests positive.  

2. **Given Data**:  
   - $P(A) = 0.01$ (Prior probability of having the disease).  
   - $P(B \mid A) = 0.95$ (Likelihood of testing positive given the disease).  
   - $P(B \mid \text{Not } A) = 1 - \text{Specificity} = 0.10$.  
   - $P(\text{Not } A) = 1 - P(A) = 0.99$.  

3. **Calculate Evidence ( $P(B)$ )**:

   $$P(B) = P(B \mid A) \cdot P(A) + P(B \mid \text{Not } A) \cdot P(\text{Not } A)$$  

   $$P(B) = (0.95 \cdot 0.01) + (0.10 \cdot 0.99) = 0.0095 + 0.099 = 0.1085$$

4. **Apply Bayes’ Theorem**:  

   $$P(A \mid B) = \frac{P(B \mid A) \cdot P(A)}{P(B)} = \frac{0.95 \cdot 0.01}{0.1085} \approx 0.0876$$

### Interpretation:  

If a person tests positive, the probability they actually have the disease is approximately 8.76%.

---

## Advantages of Bayesian Statistics

1. **Incorporates Prior Knowledge**:  
   Allows integration of existing information with new data.  

2. **Interpretable Probabilities**:  
   Provides direct probabilities for hypotheses or parameters.  

3. **Flexibility**:  
   Can handle complex models and small sample sizes.

---

## Common Applications

1. **Healthcare**:  
   - Diagnosing diseases based on test results.  
   - Analyzing clinical trial outcomes.  

2. **Machine Learning**:  
   - Bayesian networks for probabilistic modeling.  
   - Hyperparameter tuning using Bayesian optimization.  

3. **Business**:  
   - Predicting customer behavior.  
   - A/B testing for marketing strategies.  

4. **Science and Research**:  
   - Updating models with new experimental data.  

---

## Tools for Bayesian Analysis

1. **Python Libraries**:  
   - **PyMC**: Probabilistic programming.  
   - **Scikit-learn**: Naive Bayes classifiers.  
   - **Stan (via pystan)**: Bayesian modeling.

2. **R**:  
   - **BayesFactor**: Hypothesis testing.  
   - **rstan**: Bayesian modeling in R.  

3. **Specialized Software**:  
   - **BUGS**: Bayesian analysis using Gibbs Sampling.  
   - **JAGS**: Just Another Gibbs Sampler.

---

## Comparison: Bayesian vs. Frequentist Statistics

| Feature             | Bayesian Statistics                    | Frequentist Statistics                   |
|---------------------|----------------------------------------|------------------------------------------|
| **Probability**     | Represents a degree of belief          | Long-term frequency of events            |
| **Prior Knowledge** | Incorporates prior information         | Does not use prior information           |
| **Interpretation**  | Probability of a hypothesis being true | Reject or fail to reject null hypothesis |

---

## Conclusion

Bayesian statistics offers a powerful framework for updating beliefs and making decisions under uncertainty. By incorporating prior knowledge and evidence, it provides a flexible and interpretable approach to data analysis and prediction.

---

**Next Steps**: [In Business and Finance](../07.%20Applications/1.%20In%20Business%20and%20Finance.md)
