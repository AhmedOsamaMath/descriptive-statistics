# Multiple Regression

**Multiple regression** is a statistical method used to examine the relationship between a dependent variable ($Y$) and two or more independent variables ($X_1, X_2, \dots, X_k$). It extends simple linear regression to model more complex relationships.

---

## Key Concepts

1. **Dependent Variable ($Y$)**:
   The outcome or response variable we aim to predict or explain.

2. **Independent Variables ($X_1, X_2, \dots, X_k$)**:  
   The predictors or explanatory variables that influence $Y$.

3. **Regression Equation**:

   $$Y = \beta_0 + \beta_1X_1 + \beta_2X_2 + \dots + \beta_kX_k + \epsilon$$

   Where:

   - $\beta_0$: Intercept (value of $Y$ when all $X_i = 0$)  
   - $\beta_1, \beta_2, \dots, \beta_k$: Coefficients showing the effect of each $X_i$ on $Y$  
   - $\epsilon$: Error term  

---

## Assumptions of Multiple Regression

1. **Linearity**: The relationship between $Y$ and each $X_i$ is linear.  
2. **Independence**: Observations are independent of each other.  
3. **Homoscedasticity**: The variance of residuals is constant across all levels of $X_i$.  
4. **No Multicollinearity**: Independent variables are not highly correlated with each other.  
5. **Normality**: Residuals follow a normal distribution.

---

## Steps to Perform Multiple Regression

### Step 1: Formulate the Model

Define the dependent variable ($Y$) and the independent variables ($X_1, X_2, \dots, X_k$).

### Step 2: Collect and Explore Data

Examine the dataset for missing values, outliers, and potential correlations among independent variables.

### Step 3: Fit the Model

Estimate the coefficients ($\beta_0, \beta_1, \dots, \beta_k$) using the least squares method.

### Step 4: Evaluate the Model

Use metrics such as $R^2$, adjusted $R^2$, p-values, and residual analysis to assess the model's performance.

### Step 5: Interpret Results

Understand the influence of each independent variable on $Y$ based on the coefficients and their statistical significance.

---

## Example

### Problem:

A company wants to predict employee salaries ($Y$) based on years of experience ($X_1$) and education level ($X_2$).

### Dataset:

| Years of Experience ($X_1$) | Education Level ($X_2$) | Salary ($Y$) |
|-----------------------------|-------------------------|--------------|
| 2                           | 1                       | 50,000       |
| 4                           | 2                       | 60,000       |
| 6                           | 2                       | 70,000       |
| 8                           | 3                       | 85,000       |
| 10                          | 3                       | 95,000       |

### Solution:

1. **Regression Equation**:  

   $$Y = \beta_0 + \beta_1X_1 + \beta_2X_2$$

2. **Fit the Model**:

   Using statistical software or calculations, the estimated coefficients are:

   - $\beta_0 = 40,000$
   - $\beta_1 = 5,000$
   - $\beta_2 = 10,000$

3. **Regression Equation**:

   $$Y = 40,000 + 5,000X_1 + 10,000X_2$$

4. **Prediction**:

   For an employee with 7 years of experience ($X_1 = 7$) and education level 2 ($X_2 = 2$):
   
   $$Y = 40,000 + 5,000(7) + 10,000(2) = 40,000 + 35,000 + 20,000 = 95,000$$

---

## Model Evaluation Metrics

1. **R-Squared ($R^2$)**:  
   Measures the proportion of variance in $Y$ explained by all $X_i$.  

2. **Adjusted R-Squared**:  
   Accounts for the number of predictors, providing a better measure for models with multiple variables.  

3. **P-Values**:  
   Tests the significance of each predictor. If $p \leq \alpha$ (e.g., 0.05), the predictor is statistically significant.  

4. **Variance Inflation Factor (VIF)**:  
   Detects multicollinearity. Values greater than 10 indicate high multicollinearity.

---

## Applications of Multiple Regression

1. **Business**: Predicting sales based on advertising spend, price, and product quality.  
2. **Healthcare**: Estimating patient outcomes based on age, weight, and treatment type.  
3. **Education**: Analyzing student performance based on study time, attendance, and teaching methods.

---

## Visualization

- **Scatter Plot Matrix**: Shows relationships between $Y$ and each $X_i$.  
- **Residual Plot**: Helps check assumptions like linearity and homoscedasticity.  

---

## Conclusion

Multiple regression is a versatile tool for understanding complex relationships between a dependent variable and multiple predictors. By carefully checking assumptions and interpreting results, you can use this method to make accurate predictions and data-driven decisions.

---

**Next Steps**: [Logistic Regression](./3.%20Logistic%20Regression.md)
